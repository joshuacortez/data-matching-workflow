{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "# do this to be able to import the custom python scripts\n",
    "sys.path.insert(1, \"../../../python_scripts\")\n",
    "import os\n",
    "\n",
    "import dm_utils\n",
    "import dm_file_checker\n",
    "\n",
    "import dedupe\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Appropriate Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric fields are []\n"
     ]
    }
   ],
   "source": [
    "saved_files_path = \"../../../saved_files\"\n",
    "task_name = os.path.basename(os.getcwd())\n",
    "dataset_name = task_name.split(\"-\")[1]\n",
    "\n",
    "# files to read in\n",
    "primary_key = dm_file_checker.get_dataset_info(task_name, \"primary_key\", saved_files_path)\n",
    "unlabeled_data_filepath = dm_file_checker.get_filepath(task_name, \"unlabeled_data\", saved_files_path)\n",
    "unlabeled_data_no_exact_filepath = dm_file_checker.get_filepath(task_name, \"unlabeled_data_no_exact\", saved_files_path)\n",
    "\n",
    "numeric_fields = dm_file_checker.get_dataset_info(task_name, \"numeric_fields\", saved_files_path)\n",
    "print(\"Numeric fields are {}\".format(numeric_fields))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 152 ms, sys: 8.12 ms, total: 160 ms\n",
      "Wall time: 171 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>febrl4a-rec-1070-org</th>\n",
       "      <td>1915/11/11</td>\n",
       "      <td>michaela</td>\n",
       "      <td>neumann</td>\n",
       "      <td>8</td>\n",
       "      <td>stanley street</td>\n",
       "      <td>miami</td>\n",
       "      <td>winston hills</td>\n",
       "      <td>4223</td>\n",
       "      <td>nsw</td>\n",
       "      <td>5304218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>febrl4a-rec-1016-org</th>\n",
       "      <td>1916/12/14</td>\n",
       "      <td>courtney</td>\n",
       "      <td>painter</td>\n",
       "      <td>12</td>\n",
       "      <td>pinkerton circuit</td>\n",
       "      <td>bega flats</td>\n",
       "      <td>richlands</td>\n",
       "      <td>4560</td>\n",
       "      <td>vic</td>\n",
       "      <td>4066625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>febrl4a-rec-4405-org</th>\n",
       "      <td>1948/09/30</td>\n",
       "      <td>charles</td>\n",
       "      <td>green</td>\n",
       "      <td>38</td>\n",
       "      <td>salkauskas crescent</td>\n",
       "      <td>kela</td>\n",
       "      <td>dapto</td>\n",
       "      <td>4566</td>\n",
       "      <td>nsw</td>\n",
       "      <td>4365168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>febrl4a-rec-1288-org</th>\n",
       "      <td>1995/11/19</td>\n",
       "      <td>vanessa</td>\n",
       "      <td>parr</td>\n",
       "      <td>905</td>\n",
       "      <td>macquoid place</td>\n",
       "      <td>broadbridge manor</td>\n",
       "      <td>south grafton</td>\n",
       "      <td>2135</td>\n",
       "      <td>sa</td>\n",
       "      <td>9239102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>febrl4a-rec-3585-org</th>\n",
       "      <td>1986/02/08</td>\n",
       "      <td>mikayla</td>\n",
       "      <td>malloney</td>\n",
       "      <td>37</td>\n",
       "      <td>randwick road</td>\n",
       "      <td>avalind</td>\n",
       "      <td>hoppers crossing</td>\n",
       "      <td>4552</td>\n",
       "      <td>vic</td>\n",
       "      <td>7207688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date_of_birth given_name   surname street_number  \\\n",
       "febrl4a-rec-1070-org    1915/11/11   michaela   neumann             8   \n",
       "febrl4a-rec-1016-org    1916/12/14   courtney   painter            12   \n",
       "febrl4a-rec-4405-org    1948/09/30    charles     green            38   \n",
       "febrl4a-rec-1288-org    1995/11/19    vanessa      parr           905   \n",
       "febrl4a-rec-3585-org    1986/02/08    mikayla  malloney            37   \n",
       "\n",
       "                                address_1          address_2  \\\n",
       "febrl4a-rec-1070-org       stanley street              miami   \n",
       "febrl4a-rec-1016-org    pinkerton circuit         bega flats   \n",
       "febrl4a-rec-4405-org  salkauskas crescent               kela   \n",
       "febrl4a-rec-1288-org       macquoid place  broadbridge manor   \n",
       "febrl4a-rec-3585-org        randwick road            avalind   \n",
       "\n",
       "                                suburb postcode state soc_sec_id  \n",
       "febrl4a-rec-1070-org     winston hills     4223   nsw    5304218  \n",
       "febrl4a-rec-1016-org         richlands     4560   vic    4066625  \n",
       "febrl4a-rec-4405-org             dapto     4566   nsw    4365168  \n",
       "febrl4a-rec-1288-org     south grafton     2135    sa    9239102  \n",
       "febrl4a-rec-3585-org  hoppers crossing     4552   vic    7207688  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "unlabeled_data = dm_utils.read_unlabeled_data_json(unlabeled_data_filepath, numeric_fields = numeric_fields,\n",
    "                                                  empty_str_to_none = False)\n",
    "unlabeled_data = pd.DataFrame.from_dict(unlabeled_data, orient = \"index\")\n",
    "unlabeled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert null numerical fields to empty string\n",
    "for field in numeric_fields:\n",
    "    unlabeled_data[field] = unlabeled_data[field].fillna(\"\")\n",
    "    unlabeled_data[field] = unlabeled_data[field].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Duplicates in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 records that have duplicates\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = unlabeled_data.duplicated().sum()\n",
    "print(\"There are {} records that have duplicates\".format(num_duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Since no exact duplicates found, not continuing further",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-18c4da7abfc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnum_duplicates\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Since no exact duplicates found, not continuing further\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Since no exact duplicates found, not continuing further"
     ]
    }
   ],
   "source": [
    "assert num_duplicates > 0, \"Since no exact duplicates found, not continuing further\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning New ID to Same Record\n",
    "- New ID is `<dataset_name>-ex-<number>` which refer to the records with exactly the same fields.\n",
    "- ex stands for exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id_mapping = unlabeled_data.groupby(unlabeled_data.columns.tolist()).ngroup() + 1\n",
    "new_id_mapping = new_id_mapping.apply(lambda x: \"{}-ex-{}\".format(dataset_name, x))\n",
    "new_id_mapping = pd.DataFrame(new_id_mapping, columns = [primary_key])\n",
    "new_id_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_new_id = new_id_mapping[primary_key].unique().shape[0]\n",
    "print(\"Originally, there are {:,} IDs\".format(new_id_mapping.shape[0]))\n",
    "print(\"There are {:,} remaining IDs after disregarding exact duplicates\".format(n_new_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting New ID as Primary Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = pd.merge(left = new_id_mapping, right = unlabeled_data, right_index = True, left_index = True,\n",
    "                            validate = \"one_to_one\")\n",
    "unlabeled_data.index.name = \"{}_old\".format(primary_key)\n",
    "unlabeled_data = unlabeled_data.reset_index()\n",
    "unlabeled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out mapping from old primary key to new primary key\n",
    "primary_key_mapping = unlabeled_data.loc[:,[primary_key, \"{}_old\".format(primary_key)]]\n",
    "primary_key_mapping_filepath = unlabeled_data_filepath.replace(\"unlabeled_data.json\", \"primary_key_mapping_exact_duplicates.csv\")\n",
    "primary_key_mapping.to_csv(primary_key_mapping_filepath, index = False, quoting = csv.QUOTE_ALL)\n",
    "del primary_key_mapping\n",
    "\n",
    "unlabeled_data = unlabeled_data.drop(columns = \"{}_old\".format(primary_key))\n",
    "\n",
    "same_key_bool = unlabeled_data[primary_key].duplicated(keep = \"first\")\n",
    "print(\"Removing {} rows that have the same new primary key (i.e. exact duplicates)\".format(same_key_bool.sum()))\n",
    "unlabeled_data = unlabeled_data.loc[~same_key_bool,:].set_index(primary_key)\n",
    "\n",
    "unlabeled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Out New Dataset to a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure all values are strings before writing to json\n",
    "assert unlabeled_data.applymap(type).eq(str).all().all(), \"not all values are strings!\"\n",
    "\n",
    "assert unlabeled_data.isnull().sum().sum() == 0, \"still found a native Python null in the dataset!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = unlabeled_data.to_dict(orient = \"index\")\n",
    "\n",
    "with open(unlabeled_data_no_exact_filepath, \"w\") as json_file:\n",
    "    json.dump(unlabeled_data, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_matching] *",
   "language": "python",
   "name": "conda-env-data_matching-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
