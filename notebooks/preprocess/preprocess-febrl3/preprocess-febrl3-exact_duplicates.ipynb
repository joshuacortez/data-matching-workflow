{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "# do this to be able to import the custom python scripts\n",
    "sys.path.insert(1, \"../../../python_scripts\")\n",
    "import os\n",
    "\n",
    "import dm_utils\n",
    "import dm_file_checker\n",
    "\n",
    "import dedupe\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Appropriate Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric fields are []\n"
     ]
    }
   ],
   "source": [
    "saved_files_path = \"../../../saved_files\"\n",
    "task_name = os.path.basename(os.getcwd())\n",
    "dataset_name = task_name.split(\"-\")[1]\n",
    "\n",
    "# files to read in\n",
    "primary_key = dm_file_checker.get_dataset_info(task_name, \"primary_key\", saved_files_path)\n",
    "unlabeled_data_filepath = dm_file_checker.get_filepath(task_name, \"unlabeled_data\", saved_files_path)\n",
    "unlabeled_data_no_exact_filepath = dm_file_checker.get_filepath(task_name, \"unlabeled_data_no_exact\", saved_files_path)\n",
    "\n",
    "numeric_fields = dm_file_checker.get_dataset_info(task_name, \"numeric_fields\", saved_files_path)\n",
    "print(\"Numeric fields are {}\".format(numeric_fields))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 115 ms, sys: 7.83 ms, total: 123 ms\n",
      "Wall time: 135 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>febrl3-rec-1496-org</th>\n",
       "      <td>1956/04/09</td>\n",
       "      <td>mitchell</td>\n",
       "      <td>green</td>\n",
       "      <td>7</td>\n",
       "      <td>wallaby place</td>\n",
       "      <td>delmar</td>\n",
       "      <td>cleveland</td>\n",
       "      <td>2119</td>\n",
       "      <td>sa</td>\n",
       "      <td>1804974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>febrl3-rec-552-dup-3</th>\n",
       "      <td>1908/04/19</td>\n",
       "      <td>harley</td>\n",
       "      <td>mccarthy</td>\n",
       "      <td>177</td>\n",
       "      <td>pridhamstreet</td>\n",
       "      <td>milton</td>\n",
       "      <td>marsden</td>\n",
       "      <td>3165</td>\n",
       "      <td>nsw</td>\n",
       "      <td>6089216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>febrl3-rec-988-dup-1</th>\n",
       "      <td>1908/11/28</td>\n",
       "      <td>madeline</td>\n",
       "      <td>mason</td>\n",
       "      <td>54</td>\n",
       "      <td>hoseason street</td>\n",
       "      <td>lakefront retrmnt vlge</td>\n",
       "      <td>granville</td>\n",
       "      <td>4881</td>\n",
       "      <td>nsw</td>\n",
       "      <td>2185997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>febrl3-rec-1716-dup-1</th>\n",
       "      <td>1992/11/19</td>\n",
       "      <td>isabelle</td>\n",
       "      <td></td>\n",
       "      <td>23</td>\n",
       "      <td>gundulu place</td>\n",
       "      <td>currin ga</td>\n",
       "      <td>utakarra</td>\n",
       "      <td>2193</td>\n",
       "      <td>wa</td>\n",
       "      <td>4314184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>febrl3-rec-1213-org</th>\n",
       "      <td>1999/12/07</td>\n",
       "      <td>taylor</td>\n",
       "      <td>hathaway</td>\n",
       "      <td>7</td>\n",
       "      <td>yuranigh court</td>\n",
       "      <td>brentwood vlge</td>\n",
       "      <td></td>\n",
       "      <td>4220</td>\n",
       "      <td>nsw</td>\n",
       "      <td>9144092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date_of_birth given_name   surname street_number  \\\n",
       "febrl3-rec-1496-org      1956/04/09   mitchell     green             7   \n",
       "febrl3-rec-552-dup-3     1908/04/19     harley  mccarthy           177   \n",
       "febrl3-rec-988-dup-1     1908/11/28   madeline     mason            54   \n",
       "febrl3-rec-1716-dup-1    1992/11/19   isabelle                      23   \n",
       "febrl3-rec-1213-org      1999/12/07     taylor  hathaway             7   \n",
       "\n",
       "                             address_1               address_2     suburb  \\\n",
       "febrl3-rec-1496-org      wallaby place                  delmar  cleveland   \n",
       "febrl3-rec-552-dup-3     pridhamstreet                  milton    marsden   \n",
       "febrl3-rec-988-dup-1   hoseason street  lakefront retrmnt vlge  granville   \n",
       "febrl3-rec-1716-dup-1    gundulu place               currin ga   utakarra   \n",
       "febrl3-rec-1213-org     yuranigh court          brentwood vlge              \n",
       "\n",
       "                      postcode state soc_sec_id  \n",
       "febrl3-rec-1496-org       2119    sa    1804974  \n",
       "febrl3-rec-552-dup-3      3165   nsw    6089216  \n",
       "febrl3-rec-988-dup-1      4881   nsw    2185997  \n",
       "febrl3-rec-1716-dup-1     2193    wa    4314184  \n",
       "febrl3-rec-1213-org       4220   nsw    9144092  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "unlabeled_data = dm_utils.read_unlabeled_data_json(unlabeled_data_filepath, numeric_fields = numeric_fields,\n",
    "                                                  empty_str_to_none = False)\n",
    "unlabeled_data = pd.DataFrame.from_dict(unlabeled_data, orient = \"index\")\n",
    "unlabeled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert null numerical fields to empty string\n",
    "for field in numeric_fields:\n",
    "    unlabeled_data[field] = unlabeled_data[field].fillna(\"\")\n",
    "    unlabeled_data[field] = unlabeled_data[field].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Duplicates in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 records that have duplicates\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = unlabeled_data.duplicated().sum()\n",
    "print(\"There are {} records that have duplicates\".format(num_duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Since no exact duplicates found, not continuing further",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-18c4da7abfc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnum_duplicates\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Since no exact duplicates found, not continuing further\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Since no exact duplicates found, not continuing further"
     ]
    }
   ],
   "source": [
    "assert num_duplicates > 0, \"Since no exact duplicates found, not continuing further\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning New ID to Same Record\n",
    "- New ID is `<dataset_name>-ex-<number>` which refer to the records with exactly the same fields.\n",
    "- ex stands for exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id_mapping = unlabeled_data.groupby(unlabeled_data.columns.tolist()).ngroup() + 1\n",
    "new_id_mapping = new_id_mapping.apply(lambda x: \"{}-ex-{}\".format(dataset_name, x))\n",
    "new_id_mapping = pd.DataFrame(new_id_mapping, columns = [primary_key])\n",
    "new_id_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_new_id = new_id_mapping[primary_key].unique().shape[0]\n",
    "print(\"Originally, there are {:,} IDs\".format(new_id_mapping.shape[0]))\n",
    "print(\"There are {:,} remaining IDs after disregarding exact duplicates\".format(n_new_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting New ID as Primary Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = pd.merge(left = new_id_mapping, right = unlabeled_data, right_index = True, left_index = True,\n",
    "                            validate = \"one_to_one\")\n",
    "unlabeled_data.index.name = \"{}_old\".format(primary_key)\n",
    "unlabeled_data = unlabeled_data.reset_index()\n",
    "unlabeled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out mapping from old primary key to new primary key\n",
    "primary_key_mapping = unlabeled_data.loc[:,[primary_key, \"{}_old\".format(primary_key)]]\n",
    "primary_key_mapping_filepath = unlabeled_data_filepath.replace(\"unlabeled_data.json\", \"primary_key_mapping_exact_duplicates.csv\")\n",
    "primary_key_mapping.to_csv(primary_key_mapping_filepath, index = False, quoting = csv.QUOTE_ALL)\n",
    "del primary_key_mapping\n",
    "\n",
    "unlabeled_data = unlabeled_data.drop(columns = \"{}_old\".format(primary_key))\n",
    "\n",
    "same_key_bool = unlabeled_data[primary_key].duplicated(keep = \"first\")\n",
    "print(\"Removing {} rows that have the same new primary key (i.e. exact duplicates)\".format(same_key_bool.sum()))\n",
    "unlabeled_data = unlabeled_data.loc[~same_key_bool,:].set_index(primary_key)\n",
    "\n",
    "unlabeled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Out New Dataset to a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure all values are strings before writing to json\n",
    "assert unlabeled_data.applymap(type).eq(str).all().all(), \"not all values are strings!\"\n",
    "\n",
    "assert unlabeled_data.isnull().sum().sum() == 0, \"still found a native Python null in the dataset!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = unlabeled_data.to_dict(orient = \"index\")\n",
    "\n",
    "with open(unlabeled_data_no_exact_filepath, \"w\") as json_file:\n",
    "    json.dump(unlabeled_data, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_matching] *",
   "language": "python",
   "name": "conda-env-data_matching-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
