{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "# do this to be able to import the custom python scripts\n",
    "sys.path.insert(1, \"../../../python_scripts\")\n",
    "import os\n",
    "\n",
    "import dm_utils\n",
    "import dm_file_checker\n",
    "\n",
    "import dedupe\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Appropriate Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric fields are []\n"
     ]
    }
   ],
   "source": [
    "saved_files_path = \"../../../saved_files\"\n",
    "task_name = os.path.basename(os.getcwd())\n",
    "dataset_name = task_name.split(\"-\")[1]\n",
    "\n",
    "# files to read in\n",
    "primary_key = dm_file_checker.get_dataset_info(task_name, \"primary_key\", saved_files_path)\n",
    "unlabeled_data_filepath = dm_file_checker.get_filepath(task_name, \"unlabeled_data\", saved_files_path)\n",
    "unlabeled_data_no_exact_filepath = dm_file_checker.get_filepath(task_name, \"unlabeled_data_no_exact\", saved_files_path)\n",
    "\n",
    "numeric_fields = dm_file_checker.get_dataset_info(task_name, \"numeric_fields\", saved_files_path)\n",
    "print(\"Numeric fields are {}\".format(numeric_fields))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 120 ms, sys: 7.02 ms, total: 127 ms\n",
      "Wall time: 128 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>febrl4b-rec-561-dup-0</th>\n",
       "      <td>1965/10/13</td>\n",
       "      <td>elton</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>light setreet</td>\n",
       "      <td>pinehill</td>\n",
       "      <td>windermere</td>\n",
       "      <td>3212</td>\n",
       "      <td>vic</td>\n",
       "      <td>1551941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>febrl4b-rec-2642-dup-0</th>\n",
       "      <td>1939/02/12</td>\n",
       "      <td>mitchell</td>\n",
       "      <td>maxon</td>\n",
       "      <td>47</td>\n",
       "      <td>edkins street</td>\n",
       "      <td>lochaoair</td>\n",
       "      <td>north ryde</td>\n",
       "      <td>3355</td>\n",
       "      <td>nsw</td>\n",
       "      <td>8859999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>febrl4b-rec-608-dup-0</th>\n",
       "      <td>1962/02/16</td>\n",
       "      <td></td>\n",
       "      <td>white</td>\n",
       "      <td>72</td>\n",
       "      <td>lambrigg street</td>\n",
       "      <td>kelgoola</td>\n",
       "      <td>broadbeach waters</td>\n",
       "      <td>3159</td>\n",
       "      <td>vic</td>\n",
       "      <td>9731855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>febrl4b-rec-3239-dup-0</th>\n",
       "      <td>1998/06/24</td>\n",
       "      <td>elk i</td>\n",
       "      <td>menzies</td>\n",
       "      <td>1</td>\n",
       "      <td>lyster place</td>\n",
       "      <td></td>\n",
       "      <td>northwood</td>\n",
       "      <td>2585</td>\n",
       "      <td>vic</td>\n",
       "      <td>4970481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>febrl4b-rec-2886-dup-0</th>\n",
       "      <td>1992/10/16</td>\n",
       "      <td></td>\n",
       "      <td>garanggar</td>\n",
       "      <td></td>\n",
       "      <td>may maxwell crescent</td>\n",
       "      <td>springettst arcade</td>\n",
       "      <td>forest hill</td>\n",
       "      <td>2342</td>\n",
       "      <td>vic</td>\n",
       "      <td>1366884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date_of_birth given_name    surname street_number  \\\n",
       "febrl4b-rec-561-dup-0     1965/10/13      elton                        3   \n",
       "febrl4b-rec-2642-dup-0    1939/02/12   mitchell      maxon            47   \n",
       "febrl4b-rec-608-dup-0     1962/02/16                 white            72   \n",
       "febrl4b-rec-3239-dup-0    1998/06/24      elk i    menzies             1   \n",
       "febrl4b-rec-2886-dup-0    1992/10/16             garanggar                 \n",
       "\n",
       "                                   address_1           address_2  \\\n",
       "febrl4b-rec-561-dup-0          light setreet            pinehill   \n",
       "febrl4b-rec-2642-dup-0         edkins street           lochaoair   \n",
       "febrl4b-rec-608-dup-0        lambrigg street            kelgoola   \n",
       "febrl4b-rec-3239-dup-0          lyster place                       \n",
       "febrl4b-rec-2886-dup-0  may maxwell crescent  springettst arcade   \n",
       "\n",
       "                                   suburb postcode state soc_sec_id  \n",
       "febrl4b-rec-561-dup-0          windermere     3212   vic    1551941  \n",
       "febrl4b-rec-2642-dup-0         north ryde     3355   nsw    8859999  \n",
       "febrl4b-rec-608-dup-0   broadbeach waters     3159   vic    9731855  \n",
       "febrl4b-rec-3239-dup-0          northwood     2585   vic    4970481  \n",
       "febrl4b-rec-2886-dup-0        forest hill     2342   vic    1366884  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "unlabeled_data = dm_utils.read_unlabeled_data_json(unlabeled_data_filepath, numeric_fields = numeric_fields,\n",
    "                                                  empty_str_to_none = False)\n",
    "unlabeled_data = pd.DataFrame.from_dict(unlabeled_data, orient = \"index\")\n",
    "unlabeled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert null numerical fields to empty string\n",
    "for field in numeric_fields:\n",
    "    unlabeled_data[field] = unlabeled_data[field].fillna(\"\")\n",
    "    unlabeled_data[field] = unlabeled_data[field].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Duplicates in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 records that have duplicates\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = unlabeled_data.duplicated().sum()\n",
    "print(\"There are {} records that have duplicates\".format(num_duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Since no exact duplicates found, not continuing further",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-18c4da7abfc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnum_duplicates\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Since no exact duplicates found, not continuing further\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Since no exact duplicates found, not continuing further"
     ]
    }
   ],
   "source": [
    "assert num_duplicates > 0, \"Since no exact duplicates found, not continuing further\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning New ID to Same Record\n",
    "- New ID is `<dataset_name>-ex-<number>` which refer to the records with exactly the same fields.\n",
    "- ex stands for exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id_mapping = unlabeled_data.groupby(unlabeled_data.columns.tolist()).ngroup() + 1\n",
    "new_id_mapping = new_id_mapping.apply(lambda x: \"{}-ex-{}\".format(dataset_name, x))\n",
    "new_id_mapping = pd.DataFrame(new_id_mapping, columns = [primary_key])\n",
    "new_id_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_new_id = new_id_mapping[primary_key].unique().shape[0]\n",
    "print(\"Originally, there are {:,} IDs\".format(new_id_mapping.shape[0]))\n",
    "print(\"There are {:,} remaining IDs after disregarding exact duplicates\".format(n_new_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting New ID as Primary Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = pd.merge(left = new_id_mapping, right = unlabeled_data, right_index = True, left_index = True,\n",
    "                            validate = \"one_to_one\")\n",
    "unlabeled_data.index.name = \"{}_old\".format(primary_key)\n",
    "unlabeled_data = unlabeled_data.reset_index()\n",
    "unlabeled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out mapping from old primary key to new primary key\n",
    "primary_key_mapping = unlabeled_data.loc[:,[primary_key, \"{}_old\".format(primary_key)]]\n",
    "primary_key_mapping_filepath = unlabeled_data_filepath.replace(\"unlabeled_data.json\", \"primary_key_mapping_exact_duplicates.csv\")\n",
    "primary_key_mapping.to_csv(primary_key_mapping_filepath, index = False, quoting = csv.QUOTE_ALL)\n",
    "del primary_key_mapping\n",
    "\n",
    "unlabeled_data = unlabeled_data.drop(columns = \"{}_old\".format(primary_key))\n",
    "\n",
    "same_key_bool = unlabeled_data[primary_key].duplicated(keep = \"first\")\n",
    "print(\"Removing {} rows that have the same new primary key (i.e. exact duplicates)\".format(same_key_bool.sum()))\n",
    "unlabeled_data = unlabeled_data.loc[~same_key_bool,:].set_index(primary_key)\n",
    "\n",
    "unlabeled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Out New Dataset to a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure all values are strings before writing to json\n",
    "assert unlabeled_data.applymap(type).eq(str).all().all(), \"not all values are strings!\"\n",
    "\n",
    "assert unlabeled_data.isnull().sum().sum() == 0, \"still found a native Python null in the dataset!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = unlabeled_data.to_dict(orient = \"index\")\n",
    "\n",
    "with open(unlabeled_data_no_exact_filepath, \"w\") as json_file:\n",
    "    json.dump(unlabeled_data, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_matching] *",
   "language": "python",
   "name": "conda-env-data_matching-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
